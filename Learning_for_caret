#############记录一下学习caret包的过程吧，想用机器学习来做当前project的收尾，不过暂时自己能做的还比较少，总之一边学习一边思考吧########
#############参考自https://topepo.github.io/caret/index.html################

library('caret')
library(doParallel)
cl <- makePSOCKcluster(16)
registerDoParallel(cl) #并行运算非常重要，否则真是等到天昏地暗
# stopCluster(cl) 

##############可视化########################
#他这里介绍的可视化是feature的可视化，我们针对转录组蛋白组数据做的话可能不大有意义，所以直接跳过了

##############前处理########################
#第一条是创建虚拟变量
data(etitanic)
head(model.matrix(survived ~ ., data = etitanic))#虽然不属于caret包，但是model.matrix这个函数非常有意思
dummies <- dummyVars(survived ~ ., data = etitanic)#和model.matrix结果不同的在性别这一列，除此之外在colname的处理上更好一些？survived因为是想要预测的结果所以没有做处理吗？不大明白

#去除0和0变异
nzv <- nearZeroVar(mdrrDescr)#默认saveMetrics= F
filteredDescr <- mdrrDescr[, -nzv]#去除了矩阵里的零变异变量
dim(filteredDescr)

#降低变量之间的相关性
descrCor <- cor(filteredDescr)
summary(descrCor[upper.tri(descrCor)])
highlyCorDescr <- findCorrelation(descrCor, cutoff = .75)
filteredDescr <- filteredDescr[,-highlyCorDescr] #去除了高相关的，为什么要这么做呢？
descrCor2 <- cor(filteredDescr)
summary(descrCor2[upper.tri(descrCor2)])

#去除线性依赖
comboInfo <- findLinearCombos(ltfrDesign)
ltfrDesign[, -comboInfo$remove]

#中心化和缩放，补全
preProcValues <- preProcess(training, method = c("center", "scale"))#这个我熟

#特征变量转化
transformed <- spatialSign(plotSubset)
transformed <- as.data.frame(transformed)

preProcValues2 <- preProcess(training, method = "BoxCox")#给了两种方法，完全没懂在做什么

#All Together
pp_no_nzv <- preProcess(schedulingData[, -8], method = c("center", "scale", "YeoJohnson", "nzv"))#往method里加就可以了

#Class Distance Calculations#这个我完全没懂就没放上来了，之后理解了再说吧


################数据分离#######################

#1，基于结果，如下基于Species结果做的分离
trainIndex <- createDataPartition(iris$Species, p = .8, list = FALSE, times = 1)
irisTrain <- iris[ trainIndex,]
irisTest  <- iris[-trainIndex,]

#2，基于预测
startSet <- sample(1:dim(testing)[1], 5) #随了5行
samplePool <- testing[-startSet,]
start <- testing[startSet,]
newSamp <- maxDissim(start, samplePool, n = 20)#maximum dissimilarity approach，最大不相似尝试？什么玩意

#2，时间序列

#4，根据重要组（？）

#################模型训练和调整##################

#用sonar数据集做了一个示例

set.seed(998)
inTraining <- createDataPartition(Sonar$Class, p = .75, list = FALSE)#基于结果的分离，算是目前最好理解的一种分离方式吧，0.75的数据作为了训练集
training <- Sonar[ inTraining,]
testing  <- Sonar[-inTraining,]

#trainControl用来指定resampling的方法，这里的方法特别重要，之后会详细说明
fitControl <- trainControl(method = "repeatedcv", ## 10-fold CV，repeatedcv是K-fold交叉验证重复多次，别问我k-fold是什么
                           number = 10,                           
                           repeats = 10) ## repeated ten times

#train
gbmFit1 <- train(Class ~ ., data = training, #class为训练的预测目标，
                 method = "gbm", 
                 trControl = fitControl,
                 verbose = FALSE)  ## This last option is actually one for gbm() that passes through，这个参数好像是gbm模型特有的？
  
gbmFit1 #这个模型需要调的参数有number of iterations，complexity of the tree，shrinkage，n.minobsinnode，其中后两个被固定在了0.1和10（不知道处于什么样的考虑）
        #而n.trees和interaction.depth则根据表现选取出了表现最好的参数，这就是所谓的调参
        
#定制化调参程序
#创建调参网络
gbmGrid <-  expand.grid(interaction.depth = c(1, 5, 9), 
                        n.trees = (1:30)*50, 
                        shrinkage = 0.1,
                        n.minobsinnode = 20) #gbmGrid就是一个矩阵，包括模型需要的四个参数（在这里n.minobsinnode选择的20，说明n.minobsinnode的数值还是有影响的）
                                             #这里的trees有从50到1500三十组，depth有三种，共90种参数会被评估
                                             
set.seed(825)
gbmFit2 <- train(Class ~ ., data = training, 
                 method = "gbm", 
                 trControl = fitControl, 
                 verbose = FALSE, 
                 ## Now specify the exact models 
                 ## to evaluate:
                 tuneGrid = gbmGrid)
gbmFit2 #9，1200表现最好

#画Resampling的图
trellis.par.set(caretTheme())
plot(gbmFit2)  

plot(gbmFit2, metric = "Kappa")

plot(gbmFit2, metric = "Kappa", plotType = "level",
     scales = list(x = list(rot = 90)))
     
ggplot(gbmFit2)  #很重要但没什么好说的，可以用ggplot美化

#################trainControl功能##########################
#methods，有："boot", "cv", "LOOCV", "LGOCV", "repeatedcv", "timeslice", "none" and "oob"，具体是什么需要自己更进一步学习，提到的是oob，out-of-bag estimates，只能被用作random forest, bagged trees, bagged earth, bagged flexible discriminant analysis, or conditional tree forest models，不包括gbm
#number and repeats，
#verboseIter，是否输出training log
#returnData，是否saving the data into a slot called trainingData，不大明白slot是什么
#p，For leave-group out cross-validation
#对于"timeslice"方法, trainControl has options initialWindow, horizon and fixedWindow
#classProbs，在重采样期间是否应计算保留样本的类别概率
#index and indexOut，没懂
#summaryFunction，#这个参数对于性能的表现非常重要，如果分类且只有两类的话可以用summaryFunction = twoClassSummary，当如果回归或是多类别的话要怎么做呢？
#selectionFunction，
#PCAthresh, ICAcomp and k，给preProcess 的参数
#returnResamp，可以给"all", "final" or "none"
#allowParallel，默认应该就是开启的

##################选择表现的度量#############
#By default, RMSE, R2, and the mean absolute error (MAE) are computed for regression while accuracy and Kappa are computed for classification. 
#也可以自己选择度量的公式，如下
fitControl <- trainControl(method = "repeatedcv",number = 10,repeats = 10,
                           classProbs = TRUE, ## Estimate class probabilities
                           summaryFunction = twoClassSummary) #twoClassSummary即可以自己定义的表现度量公式,自己做是搞不定了，看看有没有分享的合适的函数吧。
head(twoClassSummary)#可以查看公式的内容                          

gbmFit3 <- train(Class ~ ., data = training,method = "gbm",trControl = fitControl,verbose = FALSE, 
                 tuneGrid = gbmGrid,metric = "ROC")## Specify which metric to optimize
gbmFit3

#################选择最终的参数###############
#有三种选法，best is chooses the largest/smallest value, 
#oneSE attempts to capture the spirit of Breiman et al (1984) 
#and tolerance selects the least complex model within some percent tolerance of the best value.

whichTwoPct <- tolerance(gbmFit3$results, metric = "ROC", 
                         tol = 2, maximize = TRUE)  #tol选项让我们可以寻找less complex model，For example, to select parameter values based on a 2% loss of performance
gbmFit3$results[whichTwoPct,1:6]

################提取预测和类别概率############
predict(gbmFit3, newdata = head(testing))
predict(gbmFit3, newdata = head(testing), type = "prob")

###############探索和比较Resampling Distributions########3
densityplot(gbmFit3, pch = "|")

#不同模型
svmFit <- train(Class ~ ., data = training, method = "svmRadial", trControl = fitControl, 
                 preProc = c("center", "scale"),tuneLength = 8,metric = "ROC")

rdaFit <- train(Class ~ ., data = training, method = "rda", trControl = fitControl, 
                 tuneLength = 4,metric = "ROC")
                 
resamps <- resamples(list(GBM = gbmFit3,SVM = svmFit,RDA = rdaFit))
summary(resamps)

#已知合适参数，不需要重采样
fitControl <- trainControl(method = "none", classProbs = TRUE)
gbmFit4 <- train(Class ~ ., data = training, method = "gbm", trControl = fitControl, verbose = FALSE, 
                 tuneGrid = data.frame(interaction.depth = 4, n.trees = 100,shrinkage = .1,n.minobsinnode = 20),
                 metric = "ROC")
predict(gbmFit4, newdata = head(testing))
predict(gbmFit4, newdata = head(testing), type = "prob")

#######################之后全是在介绍每个模型，面向的应用和调整的参数什么的##########


############对于CARTE的学习，拿起了又放下，拿起来又放下，持续的学习吧######33
library(mlbench)
data(Sonar)
str(Sonar[, 1:10])
set.seed(998)
colnames(Sonar)[60]<-c('test')# 瞎改一下做一个回归模型
Sonar<-Sonar[,-61]
inTraining <- createDataPartition(Sonar$test, p = .75, list = FALSE)
training <- Sonar[ inTraining,]
testing  <- Sonar[-inTraining,]

lm_fit <- train(test ~ .,
                data = training, 
                trControl = trainControl(method = "repeatedcv",
                                         number = 10,
                                         repeats = 10),
                method = "brnn")
                
test <- predict(lm_fit, testing)
postResample(pred = test, obs = testing$test) #之前不是一直不会做回归吗，其实也不会有太多的不一样，回归模型的评价指标是R^2,和平均方差什么的，ROC,AUC只有分类模型才有。
                                              #predict对测试集做一个运算，postResample则对模型在测试集上的表现做了一个评估，和训练集的表现比较还是存在挺大差异的。





#############另一次尝试#################
fitControl <- trainControl(method = "repeatedcv", #summaryFunction = multiClassSummary, 
                           number = 10,repeats =10,
                           classProbs = TRUE)
rfFit <- train(group ~ ., data = Train, method = "rf", trControl = fitControl, 
                tuneLength = 4,metric = "ROC") #随机森林模型，然而折腾了这么久还是画不出AUC来，或许我该换个小的数据集尝试

importance = varImp(rfFit,scale = FALSE) #可以看到在模型里具体因素所占的比重，这个非常有意思
importance

rf.probs = predict(rfFit,Test) #type = "prob"，不用prob得到的预测结果就是分类的结果，如果用prob，得到的结果就是分类的可能性（？）
rf.probs = predict(rfFit,Test,type = "prob")
postResample(pred = rf.probs, obs = Test$group) #看模型在测试集上的表现

#我的理解不一定对，我也想记录一下
#首先回归模型是没有AUC的，这不是回归模型的评价指标之一，这很好理解。
#其次对于多个结论的分类，默认就是Accuracy和Kappa两个指标，因为twoClassSummary是没法用的，它是针对两个结论的模型适用的评价。
#可是想要求AUC什么的，也是可以做到的，比如https://github.com/topepo/caret/issues/107提供了multiClassSummary，使用multiClassSummary 就可以计算很多东西，包括ROC，F1等等，极大的扩展了评价指标。
#可是想要画图我还是没搞懂要怎么画AUC，roc函数就要求你两水平的结果，那我想做多水平的结果画AUC是否适用？就是一个很纯粹的数学问题了，我不大明白。


